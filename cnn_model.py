# -*- coding: utf-8 -*-
"""CNN_Model

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v8UC6xxbX_pWyQ3SNVypHV3io4TfDRh5

# CNN Model
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from sklearn import preprocessing
from keras.layers import Conv1D,Flatten,MaxPooling1D,Dropout,TimeDistributed,MaxPool1D
from keras.layers import Dense,GlobalAveragePooling2D
from sklearn.preprocessing import MinMaxScaler
from keras.layers import Input
import matplotlib.pyplot as plt
import os
import pprint
import tensorflow as tf
import seaborn as sns

data_cnn = pd.read_excel('/content/ADCcode.xlsx',index_col="date", parse_dates=True)
data_cnn.head()

scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(data_cnn['close'].values.reshape(-1,1))
X = []
Y = []
window_size = 50
for i in range(1, len(data_cnn) - window_size - 1, 1):
    first = data_cnn.iloc[i, 2]
    temp = []
    temp2 = []
    for j in range(window_size):
        temp.append((data_cnn.iloc[i + j, 2] - first) / first)
    temp2.append((data_cnn.iloc[i + window_size, 2] - first) / first)
    X.append(np.array(temp).reshape(50, 1))
    Y.append(np.array(temp2).reshape(1, 1))

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)

train_X = np.array(x_train)
test_X = np.array(x_test)
train_Y = np.array(y_train)
test_Y = np.array(y_test)

train_X = train_X.reshape(train_X.shape[0], 50, 1, 1)
test_X = test_X.reshape(test_X.shape[0], 50, 1, 1)


seq_len = 50
n_features=4
n_filters=(8,8,8)
model1 = Sequential()
#add model layers
print(len(test_X))
model1.add(Conv1D(n_filters[0], kernel_size=1, activation="relu", input_shape=(50, 1)))
model1.add(Conv1D(n_filters[1], kernel_size=3, activation="relu"))
model1.add(MaxPooling1D(pool_size=2))
model1.add(Conv1D(n_filters[2], kernel_size=3, activation="relu"))
model1.add(MaxPooling1D(pool_size=2))
model1.add(Flatten())
model1.add(Dropout(0.1))
model1.add(Dense(1, activation="sigmoid"))

model1.compile(optimizer='adam', loss='mse', metrics=['mse', 'mae'])

model1.fit(train_X, train_Y, validation_data=(test_X, test_Y), epochs=40, batch_size=40, verbose=1, shuffle=True)
print(model1.evaluate(test_X, test_Y))

len_t = len(train_X)
predicted  = model1.predict(test_X)
test_Y = (test_Y[:,0])
predicted = np.array(predicted[:,0]).reshape(-1,1)
for j in range(len_t , len_t + len(test_X)):
    temp =data_cnn.iloc[j,4]
    test_Y[j - len_t] = test_Y[j - len_t] * temp + temp
    predicted[j - len_t] = predicted[j - len_t] * temp + temp
plt.plot(test_Y, color = 'black', label = ' Stock Price')
plt.plot(predicted, color = 'green', label = 'Predicted  Stock Price')
plt.title('Stock Prediction by CNN Model')
plt.xlabel('Time')
plt.ylabel(' Stock Price')
plt.legend()
plt.show()